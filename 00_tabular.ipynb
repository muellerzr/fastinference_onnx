{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabular\n",
    "\n",
    "> Methods for the tabular models, including data preperation and model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example we'll use the first five rows of the `ADULT_SAMPLE` dataset, which I have converted to a `NumPy` array below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "df = df.head().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For procs we will use the same ones from training a model:\n",
    "\n",
    "* Note: we have to load in  `Categorize` to have `np.nan` as an index to work properly. This is done automatically later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "import pickle\n",
    "with open('procs.pkl', 'rb') as handle:\n",
    "    procs = pickle.load(handle)\n",
    "    for proc in procs['Categorize']:\n",
    "        procs['Categorize'][proc][np.nan] = 0 # we can't pickle np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FillMissing(arr, procs):\n",
    "    \"Fills in missing data in `conts` and potentially generates a new categorical column\"\n",
    "    for idx, name in procs['Inputs']['conts'].items():\n",
    "        if name in procs['FillMissing']['na_dict'].keys():\n",
    "            nan = np.argwhere(arr[:,idx]!=arr[:,idx])\n",
    "            arr[:,idx][nan] = procs['FillMissing']['na_dict'][name]\n",
    "        if procs['FillMissing']['add_col']:\n",
    "            arr = np.append(arr, np.expand_dims(arr[:,4]==arr[:,4],1), 1)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"FillMissing\" class=\"doc_header\"><code>FillMissing</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>FillMissing</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Fills in missing data in `conts` and potentially generates a new categorical column"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(FillMissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = FillMissing(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k', True, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three `bool` columns were added at the end for our potential missing numerical values (if `True` they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Categorize(arr, procs):\n",
    "    \"Encodes categorical data in `arr` based on `procs`\"\n",
    "    for idx, name in procs['Inputs']['cats'].items():\n",
    "        arr[:,idx] = [procs['Categorize'][name][i] for i in arr[:,idx]]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Categorize\" class=\"doc_header\"><code>Categorize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Categorize</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Encodes categorical data in `arr` based on `procs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Categorize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k', True, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = Categorize(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0, 1902, 40,\n",
       "       ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our categorical variables are now all converted to integers. Any left as strings are not used by the model and are ignored at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Normalize(arr, procs):\n",
    "    \"Normalizes continous data in `arr` based on `procs`\"\n",
    "    for idx, name in procs['Inputs']['conts'].items():\n",
    "        arr[:,idx] = (arr[:,idx]-procs['Normalize'][name]['mean'])/procs['Normalize'][name]['std']\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Normalize\" class=\"doc_header\"><code>Normalize</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Normalize</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Normalizes continous data in `arr` based on `procs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`arr` is expected to be a `NumPy` array, while `procs` should be the pre-processing dictionary exported after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0, 1902, 40,\n",
       "       ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = Normalize(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7634343827572744, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0,\n",
       "       1902, 40, ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our continous variables have now been adjusted for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply_procs(arr, procs):\n",
    "    \"Apply test-time pre-processing on `NumPy` array input\"\n",
    "    arr = FillMissing(arr, procs)\n",
    "    arr = Categorize(arr, procs)\n",
    "    arr = Normalize(arr, procs)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"apply_procs\" class=\"doc_header\"><code>apply_procs</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>apply_procs</code>(**`arr`**, **`procs`**)\n",
       "\n",
       "Apply test-time pre-processing on `NumPy` array input"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(apply_procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific order in which the pre-processing is done must occur, as `Categorify` can increase by a few columns from `FillMissing` if multiple `is_na` columns are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "df = df.head().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, ' Private', 101320, ' Assoc-acdm', 12.0, ' Married-civ-spouse',\n",
       "       nan, ' Wife', ' White', ' Female', 0, 1902, 40, ' United-States',\n",
       "       '>=50k'], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = apply_procs(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7634343827572744, 5, 101320, 8, 12.0, 3, 0, 6, 5, ' Female', 0,\n",
       "       1902, 40, ' United-States', '>=50k', 2, True, True], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularDataset():\n",
    "    \"A tabular `NumPy` dataset based on `procs` with batch size `bs`\"\n",
    "    def __init__(self, arr, procs, bs=64):\n",
    "        \"Stores array, grabs the indicies for `cats` and `conts`, and generates batches\"\n",
    "        self.arr = arr\n",
    "        self.cat_idxs = procs['Inputs']['cats'].keys()\n",
    "        self.cont_idxs = procs['Inputs']['conts'].keys()\n",
    "        self.bs = bs\n",
    "        self.make_batches()\n",
    "        \n",
    "    def __getitem__(self, x):\n",
    "        \"Grabs one batch of data and converts it to the proper type\"\n",
    "        row = [self.batches[x][:, list(self.cat_idxs)], self.batches[x][:, list(self.cont_idxs)]]\n",
    "        row[0] = row[0].astype(np.int64)\n",
    "        row[1] = row[1].astype(np.float32)\n",
    "        return row\n",
    "        \n",
    "    def make_batches(self):\n",
    "        \"Splits data into equal sized batches, excluding the final partial\"\n",
    "        n_splits = len(self.arr)//self.bs\n",
    "        last = len(self.arr) - (len(self.arr) - (n_splits * self.bs))\n",
    "        if len(self.arr) > self.bs:\n",
    "            arrs = np.split(self.arr[:last], n_splits)\n",
    "            arrs.append(self.arr[last:])\n",
    "        else:\n",
    "            arrs = [self.arr]\n",
    "        self.batches = arrs\n",
    "        \n",
    "    def __len__(self): return len(self.arr)//self.bs + (0 if len(self.arr)%self.bs==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TabularDataset\" class=\"doc_header\"><code>class</code> <code>TabularDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TabularDataset</code>(**`arr`**, **`procs`**, **`bs`**=*`64`*)\n",
       "\n",
       "A tabular `NumPy` dataset based on `procs` with batch size `bs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TabularDataset.__init__\" class=\"doc_header\"><code>TabularDataset.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TabularDataset.__init__</code>(**`arr`**, **`procs`**, **`bs`**=*`64`*)\n",
       "\n",
       "Stores array, grabs the indicies for `cats` and `conts`, and generates batches"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TabularDataset.make_batches\" class=\"doc_header\"><code>TabularDataset.make_batches</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TabularDataset.make_batches</code>()\n",
       "\n",
       "Splits data into equal sized batches, excluding the final partial"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TabularDataset.make_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "df = df.head().to_numpy()\n",
    "df = apply_procs(df, procs)\n",
    "dset = TabularDataset(df, procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5,  8,  3,  0,  6,  5,  2],\n",
       "        [ 5, 13,  1,  5,  2,  5,  2],\n",
       "        [ 5, 12,  1,  0,  5,  3,  1],\n",
       "        [ 6, 15,  3, 11,  1,  2,  2],\n",
       "        [ 7,  6,  3,  9,  6,  3,  1]]),\n",
       " array([[ 7.6343441e-01,  1.0132000e+05,  1.2000000e+01],\n",
       "        [ 3.9686874e-01,  2.3674600e+05,  1.4000000e+01],\n",
       "        [-4.3010049e-02,  9.6185000e+04,  1.0000000e+01],\n",
       "        [-4.3010049e-02,  1.1284700e+05,  1.5000000e+01],\n",
       "        [ 2.5024247e-01,  8.2297000e+04,  1.0000000e+01]], dtype=float32)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class tabular_learner():\n",
    "    \"A `Learner`-like wrapper for tabular data\"\n",
    "    def __init__(self, fn):\n",
    "        \"Accepts a `fn` pointing to exported `procs` and ONNX filename\"\n",
    "        self.ort_session = ort.InferenceSession(fn+'.onnx')\n",
    "        try:\n",
    "            self.ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "            cpu = False\n",
    "        except:\n",
    "            self.ort_session.set_providers(['CPUExecutionProvider'])\n",
    "            cpu = True\n",
    "        with open(f'{fn}.pkl', 'rb') as handle:\n",
    "            self.procs = pickle.load(handle)\n",
    "            for proc in self.procs['Categorize']:\n",
    "                self.procs['Categorize'][proc][np.nan] = 0 # we can't pickle np.nan\n",
    "            \n",
    "    def test_dl(self, test_items, bs=64):\n",
    "        \"Applies `procs` to `test_items`\"\n",
    "        dl = apply_procs(test_items, self.procs)\n",
    "        return TabularDataset(dl, self.procs, bs=bs)\n",
    "    \n",
    "    def predict(self, inps):\n",
    "        \"Predict a single numpy item\"\n",
    "        names = [i.name for i in self.ort_session.get_inputs()]\n",
    "        xs = {name:x for name,x in zip(names,inps)}\n",
    "        outs = self.ort_session.run(None, xs)\n",
    "        outs = np.argmax(outs[0], axis=1)\n",
    "        outs = [learn.procs['Outputs'][i] for i in outs]\n",
    "        return outs\n",
    "    \n",
    "    def get_preds(self, dl=None):\n",
    "        \"Predict on multiple batches of data in `dl`\"\n",
    "        outs = []\n",
    "        for i, batch in enumerate(dl):\n",
    "            outs += self.predict(batch)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"tabular_learner\" class=\"doc_header\"><code>class</code> <code>tabular_learner</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>tabular_learner</code>(**`fn`**)\n",
       "\n",
       "A `Learner`-like wrapper for tabular data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.__init__\" class=\"doc_header\"><code>tabular_learner.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.__init__</code>(**`fn`**)\n",
       "\n",
       "Accepts a `fn` pointing to exported `procs` and ONNX filename"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "learn = tabular_learner('procs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.test_dl\" class=\"doc_header\"><code>tabular_learner.test_dl</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.test_dl</code>(**`test_items`**, **`bs`**=*`64`*)\n",
       "\n",
       "Applies `procs` to `test_items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "df = pd.read_csv('/home/ml1/.fastai/data/adult_sample/adult.csv')\n",
    "dl = learn.test_dl(df.iloc[:5].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 5,  8,  3,  0,  6,  5,  2],\n",
       "        [ 5, 13,  1,  5,  2,  5,  2],\n",
       "        [ 5, 12,  1,  0,  5,  3,  1],\n",
       "        [ 6, 15,  3, 11,  1,  2,  2],\n",
       "        [ 7,  6,  3,  9,  6,  3,  1]]),\n",
       " array([[ 7.6343441e-01,  1.0132000e+05,  1.2000000e+01],\n",
       "        [ 3.9686874e-01,  2.3674600e+05,  1.4000000e+01],\n",
       "        [-4.3010049e-02,  9.6185000e+04,  1.0000000e+01],\n",
       "        [-4.3010049e-02,  1.1284700e+05,  1.5000000e+01],\n",
       "        [ 2.5024247e-01,  8.2297000e+04,  1.0000000e+01]], dtype=float32)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "dl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.predict\" class=\"doc_header\"><code>tabular_learner.predict</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.predict</code>(**`inps`**)\n",
       "\n",
       "Predict a single numpy item"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<50k', '<50k', '<50k', '<50k', '<50k']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "learn.predict(dl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"tabular_learner.get_preds\" class=\"doc_header\"><code>tabular_learner.get_preds</code><a href=\"__main__.py#L32\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>tabular_learner.get_preds</code>(**`dl`**=*`None`*)\n",
       "\n",
       "Predict on multiple batches of data in `dl`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(tabular_learner.get_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<50k', '<50k', '<50k', '<50k', '<50k']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
